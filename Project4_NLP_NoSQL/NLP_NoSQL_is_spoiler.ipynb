{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f623ebc-9de9-4a07-b322-eaeacfffb1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36e30c-194a-4ad1-8a0a-314de91be3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(\"mongodb://localhost:27017/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb38bb4-93e5-4ac7-92a9-4a37cbe46aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdbDB = client[\"IMDB\"]\n",
    "movie_details_collection = imdbDB[\"Movie Details\"]\n",
    "movie_reviews_collection = imdbDB[\"Movie Reviews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250bff35-3611-4b0b-9281-6390b31cacd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDetails = [json.loads(line) for line in open('IMDB_movie_details.json', 'r')]\n",
    "movieReviews = [json.loads(line) for line in open('IMDB_reviews.json', 'r')]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f993e127-4e31-497b-b3e9-e907ca09ef95",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_details_collection.insert_many(movieDetails)\n",
    "movie_reviews_collection.insert_many(movieReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a77a82-6192-4273-932d-787ea7445bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "query1 = movie_details_collection.find()\n",
    "query2 = movie_reviews_collection.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a07652-8147-48dc-bee4-c20415ce44e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDetailsDF = pd.json_normalize(list(query1))\n",
    "movieReviewsDF = pd.json_normalize(list(query2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9a751f-6e02-4cbd-b526-767b1339786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDetailsDF.to_csv(\"movieDetails.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287806bd-2f2c-4680-af46-de2697ab4437",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieReviewsDF.to_csv(\"movieReviews.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1e46fb-e86a-4eac-b9ce-17c67810ef0d",
   "metadata": {},
   "source": [
    "## READING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899a9beb-6a4b-416b-b88d-14e2f845a34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d8f7c-56d0-48d3-b13e-62861b77488b",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDetails_DF = pd.read_csv(\"movieDetails.csv\")\n",
    "movieReviews_DF = pd.read_csv(\"movieReviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d06cf7-4071-47fd-a852-704261932eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieDetails_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c937bd-67cb-4ff2-9a30-b35455be4079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "movieDetails_DF.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4926679-6e24-4d66-9490-354fbb9ccaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieReviews_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45cc67-82c2-4c30-a970-cf6b752cb7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieReviews_DF.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f095eb-a6bb-48ea-a0a0-044157cf7c91",
   "metadata": {},
   "source": [
    "### CLEANING AND PREPROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264034c3-0411-4f44-bf95-e7edc075fcd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieReviews_DF = movieReviews_DF.sort_values(\"review_date\",ascending = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5261f-3a82-44bf-8c2e-edd1d6f0932c",
   "metadata": {},
   "outputs": [],
   "source": [
    "movieReviews_DF = movieReviews_DF.tail(2000)\n",
    "movieReviews_DF[\"is_spoiler\"].replace({False:0 ,True :1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a40007-03e9-44ca-b25c-84fb2f1ce0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text preprocessing steps - remove numbers, captial letters and punctuation\n",
    "alphanumeric = lambda x: re.sub('\\w*\\d\\w*', ' ', x)\n",
    "punc_lower = lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x.lower())\n",
    "\n",
    "movieReviews_DF['review_text'] = movieReviews_DF.review_text.map(alphanumeric).map(punc_lower)\n",
    "movieReviews_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8626dfd4-79b4-4b6d-91c0-4238ff39250b",
   "metadata": {},
   "source": [
    "## MODELING DATA WITH COUNT VECTORIZER (CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35d8dc7-43da-43f2-adc1-6f3e90b1ac2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = movieReviews_DF.review_text\n",
    "y = movieReviews_DF.is_spoiler\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:1600], X[1600:], y[:1600], y[1600:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f55553-0fbc-46ba-b79e-876f58f19343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first document-term matrix has default Count Vectorizer values - counts of unigrams\n",
    "cv1 = CountVectorizer(stop_words='english')\n",
    "\n",
    "X_train_cv1 = cv1.fit_transform(X_train)\n",
    "X_test_cv1  = cv1.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train_cv1.toarray(), columns=cv1.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a605043-1c95-44a8-9e15-c4186aff7687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second document-term matrix has both unigrams and bigrams, and indicators instead of counts\n",
    "cv2 = CountVectorizer(ngram_range=(1,2), binary=True, stop_words='english')\n",
    "\n",
    "X_train_cv2 = cv2.fit_transform(X_train)\n",
    "X_test_cv2  = cv2.transform(X_test)\n",
    "\n",
    "pd.DataFrame(X_train_cv2.toarray(), columns=cv2.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f9ded-b86c-401e-8507-1ca7bcf9f1da",
   "metadata": {},
   "source": [
    "#### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff3b7c-1e45-4b82-aa4d-2b7384de39f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "# Train the first model\n",
    "lr.fit(X_train_cv1, y_train)\n",
    "y_pred_cv1 = lr.predict(X_test_cv1)\n",
    "\n",
    "# Train the second model\n",
    "lr.fit(X_train_cv2, y_train)\n",
    "y_pred_cv2 = lr.predict(X_test_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e28c9-337e-4043-9f3f-921fe42347a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to calculate the error metrics, since we'll be doing this several times\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "def conf_matrix(actual, predicted):\n",
    "    cm = confusion_matrix(actual, predicted)\n",
    "    sns.heatmap(cm, xticklabels=['predicted_negative', 'predicted_positive'], \n",
    "                yticklabels=['actual_negative', 'actual_positive'], annot=True,\n",
    "                fmt='d', annot_kws={'fontsize':20}, cmap=\"YlGnBu\");\n",
    "\n",
    "    true_neg, false_pos = cm[0]\n",
    "    false_neg, true_pos = cm[1]\n",
    "\n",
    "    accuracy = round((true_pos + true_neg) / (true_pos + true_neg + false_pos + false_neg),3)\n",
    "    precision = round((true_pos) / (true_pos + false_pos),3)\n",
    "    recall = round((true_pos) / (true_pos + false_neg),3)\n",
    "    f1 = round(2 * (precision * recall) / (precision + recall),3)\n",
    "\n",
    "    cm_results = [accuracy, precision, recall, f1]\n",
    "    return cm_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b6ecd-1894-4806-b2d9-df42273eec03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The heat map for the first logistic regression model\n",
    "cm1 = conf_matrix(y_test, y_pred_cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db94fa6-8bf9-4589-9d7f-bb2b22187d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The heat map for the second logistic regression model\n",
    "cm2 = conf_matrix(y_test, y_pred_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7f6ce6-61f2-47e7-acb6-7b8fdf7d2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all of the error metrics into a dataframe for comparison\n",
    "results = pd.DataFrame(list(zip(cm1, cm2)))\n",
    "results = results.set_index([['Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "results.columns = ['LogReg1', 'LogReg2']\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35809eea-c4a8-4ac8-a74a-3456f2a3042e",
   "metadata": {},
   "source": [
    "#### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f49331-62fa-4489-954e-074ee731216e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_cv1, y_train)\n",
    "\n",
    "y_pred_cv1_nb = mnb.predict(X_test_cv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe464ff-0cc0-4101-8e06-24a3c1eec6bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_cv2, y_train)\n",
    "\n",
    "y_pred_cv2_nb = bnb.predict(X_test_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fbbe8e-c132-41b3-b983-6d4db6515093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the heat map for the first Naive Bayes model\n",
    "cm3 = conf_matrix(y_test, y_pred_cv1_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6700de-f8e9-4438-9978-213a8ab1cc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the heat map for the second Naive Bayes model\n",
    "cm4 = conf_matrix(y_test, y_pred_cv2_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268b61b1-3e72-4d82-8a1b-1ba31fe589b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all of the error metrics into a dataframe for comparison\n",
    "results_nb = pd.DataFrame(list(zip(cm3, cm4)))\n",
    "results_nb = results_nb.set_index([['Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "results_nb.columns = ['NB1', 'NB2']\n",
    "results_nb\n",
    "\n",
    "results = pd.concat([results, results_nb], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6a8fc7-9a21-46cd-aeae-bb8c89fc7b80",
   "metadata": {},
   "source": [
    "## MODELING DATA WITH TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752379f-0abb-41c7-892f-2dd7e0089484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create TF-IDF versions of the Count Vectorizers created earlier in the exercise\n",
    "\n",
    "tfidf1 = TfidfVectorizer(stop_words='english')\n",
    "X_train_tfidf1 = tfidf1.fit_transform(X_train)\n",
    "X_test_tfidf1  = tfidf1.transform(X_test)\n",
    "\n",
    "tfidf2 = TfidfVectorizer(ngram_range=(1,2), binary=True, stop_words='english')\n",
    "X_train_tfidf2 = tfidf2.fit_transform(X_train)\n",
    "X_test_tfidf2  = tfidf2.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798815b8-04a5-46bc-9e7a-c11218f30905",
   "metadata": {},
   "source": [
    "#### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beebac69-bd8c-4423-bb2b-b74ffaf3312f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the first logistic regression on the TF-IDF data\n",
    "lr.fit(X_train_tfidf1, y_train)\n",
    "y_pred_tfidf1_lr = lr.predict(X_test_tfidf1)\n",
    "cm5 = conf_matrix(y_test, y_pred_tfidf1_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0702c209-e4c4-4341-81cc-0b6786b7d8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the second logistic regression on the TF-IDF data\n",
    "lr.fit(X_train_tfidf2, y_train)\n",
    "y_pred_tfidf2_lr = lr.predict(X_test_tfidf2)\n",
    "cm6 = conf_matrix(y_test, y_pred_tfidf2_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41320065-c11e-4728-8e36-77bd37c37b53",
   "metadata": {},
   "source": [
    "#### NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41560ad-15cf-4c29-9543-1b05bbb837d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the first Naive Bayes model on the TF-IDF data\n",
    "mnb.fit(X_train_tfidf1.toarray(), y_train)\n",
    "y_pred_tfidf1_nb = mnb.predict(X_test_tfidf1)\n",
    "cm7 = conf_matrix(y_test, y_pred_tfidf1_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87c671c-299e-490b-a0dd-508867493f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the second Naive Bayes model on the TF-IDF data\n",
    "bnb.fit(X_train_tfidf2.toarray(), y_train)\n",
    "y_pred_tfidf2_nb = bnb.predict(X_test_tfidf2)\n",
    "cm8 = conf_matrix(y_test, y_pred_tfidf2_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127221c-59ce-45a0-b852-6018078f8ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile all of the error metrics into a dataframe for comparison\n",
    "results_tf = pd.DataFrame(list(zip(cm5, cm6, cm7, cm8)))\n",
    "results_tf = results_tf.set_index([['Accuracy', 'Precision', 'Recall', 'F1 Score']])\n",
    "results_tf.columns = ['LR1-TFIDF', 'LR2-TFIDF', 'NB1-TFIDF', 'NB2-TFIDF']\n",
    "results_tf\n",
    "\n",
    "results = pd.concat([results, results_tf], axis=1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9521a6-27ec-4ff2-ae92-7475a2b578db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
